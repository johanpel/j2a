{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unexpected-compound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: 44em; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>div.output_scroll { height: 44em; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "august-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(path):\n",
    "    props = os.path.splitext(os.path.basename(path))[0].split('_')\n",
    "    values = [int(x[1:]) for x in props[1:]]\n",
    "\n",
    "    return {'max_value':values[0],\n",
    "            'threads':values[1],\n",
    "            'input_size_approx':values[2],\n",
    "            'repeats':values[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "blank-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file):\n",
    "    \"\"\"Load the experiment data from a CSV file with converter metrics.\"\"\"\n",
    "        \n",
    "    schema = {\n",
    "        'num_threads': np.int64(),\n",
    "        'num_jsons_converted': np.int64(),\n",
    "        'num_json_bytes_converted': np.int64(),\n",
    "        'num_recordbatch_bytes': np.int64(),\n",
    "        'num_ipc': np.int64(),\n",
    "        'ipc_bytes': np.int64(),\n",
    "        'num_buffers_converted': np.int64(),\n",
    "        't_parse': np.float64(),\n",
    "        't_resize': np.float64(),\n",
    "        't_serialize': np.float64(),\n",
    "        't_thread': np.float64(),\n",
    "        't_enqueue': np.float64(),\n",
    "        'status': np.int64()\n",
    "    }\n",
    "    \n",
    "    display('Reading: {}'.format(file))\n",
    "    \n",
    "    df = pd.read_csv(file, dtype=schema)\n",
    "    \n",
    "    meta = get_meta(file)\n",
    "\n",
    "    for key, value in meta.items():  \n",
    "        df.insert(0, key, value)\n",
    "        \n",
    "    # Make sure there were no errors for converters.\n",
    "    assert(df['status'].sum() == len(df.index))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thirty-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(df):\n",
    "    \"\"\"Analyze the experiment data, deriving various metrics such as throughput.\"\"\"\n",
    "    # Calculate time spent within the thread as 'other'.\n",
    "    df['t_other'] = df['t_thread'] - df[['t_parse', 't_resize', 't_serialize', 't_enqueue']].sum(axis=1)\n",
    "    \n",
    "    # Calculate the throughput per thread\n",
    "    df['Parse throughput (in)'] = df['num_json_bytes_converted'] / df['t_parse']\n",
    "    df['Parse throughput (out)'] = df['num_recordbatch_bytes'] / df['t_parse']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mobile-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(df):\n",
    "    \"\"\"Summarize the data from one run into one row with averages.\"\"\"\n",
    "    \n",
    "    assert(len(pd.unique(df['max_value'])==1))\n",
    "    assert(len(pd.unique(df['threads'])==1))\n",
    "    assert(len(pd.unique(df['input_size_approx'])==1))\n",
    "    assert(df['num_threads'].sum()==pd.unique(df['threads'])[0])\n",
    "    repeats = pd.unique(df['repeats'])[0]\n",
    "    \n",
    "    row = {'Max. value': pd.unique(df['max_value'])[0],\n",
    "           'Input size': pd.unique(df['input_size_approx'])[0],\n",
    "           'Repeats': pd.unique(df['repeats'])[0],\n",
    "           'Threads': df['num_threads'].sum(),\n",
    "           'JSONs': df['num_jsons_converted'].sum() / repeats,\n",
    "           'Bytes (in)': df['num_json_bytes_converted'].sum() / repeats,\n",
    "           'RecordBatch bytes': df['num_recordbatch_bytes'].sum() / repeats,\n",
    "           'IPC messages': df['num_ipc'].sum() / repeats,\n",
    "           'IPC bytes': df['ipc_bytes'].sum() / repeats,\n",
    "           'Buffers converted': df['num_buffers_converted'].sum() / repeats,\n",
    "           # For time, we use the max time of all threads, \n",
    "           # since the throughput is determined by the slowest thread in the pool,\n",
    "           # and they all start operating simultaneously\n",
    "           'Parse time': df['t_parse'].max(),\n",
    "           'Resize time': df['t_resize'].max(),\n",
    "           'Serialize time': df['t_serialize'].max(),\n",
    "           'Enqueue time': df['t_enqueue'].max(),\n",
    "           'Other time': df['t_other'].max(),\n",
    "           'Thread time': df['t_thread'].max(),\n",
    "           'Parse throughput (in)': df['num_json_bytes_converted'].sum() / df['t_parse'].max(),\n",
    "           'Parse throughput (out)': df['num_recordbatch_bytes'].sum() / df['t_parse'].max()}\n",
    "              \n",
    "    return row;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "organizational-entrepreneur",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_all_data(data_path, schema, impl):\n",
    "    path = '{}/{}/latency/threads/metrics/{}/'.format(data_path, schema, impl.lower())\n",
    "    csv_files = []\n",
    "    for file in glob.glob(\"{}*.csv\".format(path)):\n",
    "        csv_files.append(file)\n",
    "    print(\"Found {} files in {}\".format(len(csv_files), path))\n",
    "\n",
    "    records = []\n",
    "    for file in csv_files:\n",
    "        records.append(summarize(analyze(load(file))))\n",
    "\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df.sort_values(by=['Threads', 'JSONs'], inplace=True)\n",
    "    df.insert(0,'Implementation', impl)\n",
    "    \n",
    "    # Use only best value\n",
    "    df = df[df['Max. value'] == 18446744073709551615]\n",
    "    \n",
    "    # Print max throughput\n",
    "    display(df['Parse throughput (in)'].max())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extreme-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_throughput_for_max_size(df):\n",
    "    df = df[df.JSONs == df.JSONs.max()]\n",
    "    #df.set_index('Threads', inplace=True)\n",
    "\n",
    "    result = df[df['Parse throughput (in)'] == df['Parse throughput (in)'].max()]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "generic-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import lighten_color\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "    \"font.size\": 14\n",
    "})\n",
    "\n",
    "colors = ['#4878d0', '#6acc64', '#d65f5f', '#d5bb67', '#dc7ec0', '#8c613c']\n",
    "markers = ['o', 's', 'd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mounted-short",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 files in ../experiments/data-sigmax/trip/latency/threads/metrics/arrow/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Reading: ../experiments/data-sigmax/trip/latency/threads/metrics/arrow/metrics_m18446744073709551615_t1_s16777216_r8.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Reading: ../experiments/data-sigmax/trip/latency/threads/metrics/arrow/metrics_m18446744073709551615_t12_sNone_r8.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'None'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bf951860a725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0md_impls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0md_impls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../experiments/data-sigmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Arrow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0md_impls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../experiments/data-sigmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Custom'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0md_impls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../experiments/data-sigmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FPGA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-8fc8a734f3de>\u001b[0m in \u001b[0;36mget_all_data\u001b[0;34m(data_path, schema, impl)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mrecords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c0cbf63595c1>\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2e75731f0d6d>\u001b[0m in \u001b[0;36mget_meta\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     return {'max_value':values[0],\n",
      "\u001b[0;32m<ipython-input-2-2e75731f0d6d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     return {'max_value':values[0],\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'None'"
     ]
    }
   ],
   "source": [
    "d_impls = []\n",
    "\n",
    "d_impls.append(get_all_data('../experiments/data-sigmax', 'trip', 'Arrow'))\n",
    "d_impls.append(get_all_data('../experiments/data-sigmax', 'trip', 'Custom'))\n",
    "d_impls.append(get_all_data('../experiments/data-sigmax', 'trip', 'FPGA'))\n",
    "\n",
    "df = pd.concat(d_impls)\n",
    "\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n",
    "display(df)\n",
    "\n",
    "# Get all dimensions for plots\n",
    "#max_values = pd.unique(df['Max. value'])\n",
    "#max_num_values = pd.unique(df['Max. number of values'])\n",
    "value_bytes = np.sort(pd.unique(df['Value bytes']))\n",
    "input_sizes = np.sort(pd.unique(df['Input size']))\n",
    "threads = np.sort(pd.unique(df['Threads']))\n",
    "impls = pd.unique(df['Implementation'])\n",
    "\n",
    "print(\"Value bytes    :\", value_bytes)\n",
    "print(\"Input sizes    :\", input_sizes)\n",
    "print(\"Threads        :\", threads)\n",
    "print(\"Impls          :\", impls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-forum",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len(value_bytes), ncols=len(input_sizes), figsize=(2.5 * len(input_sizes), 2.5 * len(value_bytes)), sharey=True, sharex=True)\n",
    "\n",
    "handles = {}\n",
    "\n",
    "for xa, inps in enumerate(input_sizes):\n",
    "    for ya, valb in enumerate(value_bytes):\n",
    "        ax = axs[ya][xa]\n",
    "                \n",
    "        for i, impl in enumerate(impls):\n",
    "            # Prepare plotting data\n",
    "            dl = df[(df['Value bytes'] == valb) & (df['Input size'] == inps) & (df['Implementation'] == impl)]\n",
    "            y = dl['Parse throughput (in)'] * 1e-9\n",
    "            x = dl['Threads']\n",
    "            \n",
    "            # Plot FPGA data\n",
    "            handles[impl], = ax.plot(x, y, c=lighten_color(colors[i],0.3), marker=markers[i], mfc=colors[i], mec=colors[i], linewidth=3)\n",
    "            \n",
    "            if impl == 'FPGA':\n",
    "                ax.axhline(y=y.to_numpy()[-1], color=lighten_color(colors[i],0.7))\n",
    "            \n",
    "            \n",
    "            \n",
    "        # Set inline \n",
    "        ax.annotate(\"V:{:.1f} B\\nS:{:.0f} MiB\".format(valb, inps / (1<<20)), \n",
    "                    xycoords='axes fraction', \n",
    "                    xy=(0.05, 0.775), \n",
    "                    fontsize=12,\n",
    "                    backgroundcolor='#FFFFFF80')\n",
    "        \n",
    "        ax.set_xticks(threads)\n",
    "        ax.set_xticklabels(threads, rotation=90, fontsize=8)\n",
    "        \n",
    "        ax.set_yticks(range(0, 25,4))\n",
    "        ax.set_ylim(0, 25)\n",
    "        \n",
    "        ax.grid(which='both')\n",
    "        \n",
    "        if (ya == len(value_bytes) - 1) and (xa == 0):\n",
    "            ax.set_xlabel('Threads / Parser instances')\n",
    "            ax.set_ylabel('Throughput (GB/s)')\n",
    "                        \n",
    "leg_handles = [v for k,v in handles.items()]\n",
    "leg_labels = [k for k,v in handles.items()]\n",
    "fig.legend(leg_handles, leg_labels, ncol=3, bbox_to_anchor=(-0.25, 0.83, 1.0, 0.1))\n",
    "plt.subplots_adjust(hspace = .1, wspace = .075)\n",
    "\n",
    "fig.savefig(\"throughput.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-diabetes",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
